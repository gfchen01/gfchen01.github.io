[{"authors":null,"categories":null,"content":"Guofei Chen is pursuing the Master’s of Robotics at Carnegie Mellon University. He is interested in making mobile robots useful in real-world.\nDownload my resumé .\n","date":1709251200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1709251200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Guofei Chen is pursuing the Master’s of Robotics at Carnegie Mellon University. He is interested in making mobile robots useful in real-world.\nDownload my resumé .","tags":null,"title":"Guofei Chen","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://gfchen01.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Botao He","Guofei Chen","Wenshan Wang","Ji Zhang","Cornelia Fermuller","Yiannis Aloimonos"],"categories":null,"content":" ","date":1709251200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709251200,"objectID":"371f72344eea2a67910f7fb74b32319b","permalink":"https://gfchen01.github.io/publication/interactivefar/","publishdate":"2024-03-01T00:00:00Z","relpermalink":"/publication/interactivefar/","section":"publication","summary":"A efficient navigation system that takes manipulating movable object into account in complex unknown environments.","tags":[],"title":"Interactive-FAR: Interactive, Fast and Adaptable Routing for Navigation Among Movable Obstacles in Complex Unknown Environments","type":"publication"},{"authors":["Zhichao Chen","Hao Wang","Guofei Chen","Le Yao","Zhiqiang Ge","Zhihuan Song"],"categories":null,"content":" ","date":1667260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667260800,"objectID":"878a8d556ea2c5e6ba2a6b242de3bf99","permalink":"https://gfchen01.github.io/publication/oc_ndplvm/","publishdate":"2022-11-01T00:00:00Z","relpermalink":"/publication/oc_ndplvm/","section":"publication","summary":"Nonlinear Dynamical Probabilistic Latent Variable Model (NDPLVM) and its variants, essential in industrial inferential sensors, face challenges in latent space inference and deep learning (DL) backend implementation. The first issue arises from the assumption that covariates directly infer the latent variable, potentially leading to inaccuracies. The second issue involves the discrepancy between the probabilistic distribution function form of NDPLVMs and data sample-based operation of DL backends. Addressing these,this study introduces the Optimal Control-NDPLVM(OC-NDPLVM), a model designed to enhance performance by analyzing NDPLVMs learning and tackling these issues. For the first problem, NDPLVMs’ learning is reinterpreted as an optimization problem, solved by alternating direction method of multipliers, and selecting the inference network’s input via studying optimal solution’s structure. To address the second issue, OC-NDPLVM adapts mean and covariance equations for compatibility with DL backends. This model’s effectiveness is validated through experiments on two inferential sensor datasets.","tags":[],"title":"Analyzing and Improving Supervised Nonlinear Dynamical Probabilistic Latent Variable Model for Inferential Sensors","type":"publication"},{"authors":null,"categories":null,"content":"Visibility Graph Algorithm for RoboCup Small Size League Introduction based on Visibility RoboCup SSL is a platform that asks participants to design robots and compete autonomously on playing soccer. Participants have to obey restrictions on robots’ themselves and rules during game play. You can find details here. The most worth noticing facts are (for software group):\nRobot design: a robot must fit inside a 0.18 meters wide and 0.15 meters high cylinder at any point in time. A dribbling device is permitted under certain restrictions. A vision pattern is a needed for robot identification. Perception: both teams share the same vision information provided by SSL, which contains the robots’ id and pose. (Extra devices are allowed, e.g., IMU) and referee instructions are sent by a software called referee box. I am a member of ZJUNlict, the 2nd best team in the history in hall of fame, and probably the best team in recent 5 years. You may find this video of the race helpful, and you can find our team description paper here, which can give you an overview of our hardware design and competition philosophy.\nIn this blog I will talk about path planning in SSL and propose a mapping \u0026amp; planning method to address the problem better. Of course, path planning is not the main challenge in the environment. But in my opinion, there are two drawbacks of current algorithm: RRT*. First, the sampling process in RRT* is inefficient in a very sparse environment in SSL matches, as there are only limited kind and number of obstacles on the field. Second, RRT* is asymptotically optimal, which is harmful to decision in some circumstances. Take a look at the figure below.\nThe former is proposed, and the latter is RRT*. The outcome of RRT* is not always the same as it samples the field, but in this occasion, which is pretty common in matches (imagine other cars are defending the **F** car), this outcome occurs frequently. But if we build the graph based on visibility, we can get an almost optimal path in a deterministic algorithm. By the way, it is also much more efficient, and we may compare the planning time of RRT* and my proposed algorithm in the above circumstance: RRT* (averaging 31 plannings) Proposed(averaging 31 plannings) 2.338 ms 0.411 ms The next part introduces the details of proposed mapping and planning algorithm.\nMapping \u0026amp; Planning Algorithm Problem Formulation Given an initial position $I$, a target position $G$, a finite map $M$. Output a path $P$ in the map $M$ so that when the robot follows $P$, it can reach the target position $G$ and avoid collision with obstacles on $M$.\nMapping details The mapping \u0026amp; planning module could receive the pose of all the robots on the field, also the state of race (e.g., ball placement, penalty, or normal state). The module plan the path of each robot separately, i.e., one robot at a time. I do not use a grid map here; keep it in mind that there are only 3 kinds of obstacles in the field, I suggest we should represent them in the minimal representation of the geometric shapes below: (obstacles are drawn in green lines below)\nCircles, for robots\nRectangles, for the penalty area (robots are not allowed in penalty except the goalie)\nLong circle, for ball placement restricted area (During ball placement state, all robots of the non-placing team have to keep at least 0.5 meters distance to the line between the ball and the placement position)\nPlanning details We can detect if a robot will collide the above geometric shapes when: a. moving on a line segment in the field; b. at a certain position. We can do this in O(1) by checking the minimal distance between the robot and the geometric shape. The planning algorithm stores points as a graph using a KD Tree.\nPlease do note that “Sample_and_addPoints” function will make changes to the graph, so the number of nodePairs also changes in the outer loop. Here is the detail of $Sample_and_addPoints$:\nThis is expressed in recursion for convenience. This algorithm will first check if the obstacle is marked (to make sure this will stop), then sample around the obstacle, and check each sampled point whether it will lead to collision with any other obstacles. If not, add the point to the graph; if it leads to collision, check each obstacle that the point collides with whether they are marked. If they aren’t marked, call the algorithm recursively on it.\nThe BuildGraph algorithm aims to achieve the following goal:\nFor any pair of nodes in the graph, either the edge between them is collision-free, or the obstacles that could cause collision are sampled.\nHere is an example. The graph is marked in green, the target is always the point at right.\nAssume F car is going to the point connected with purple line:\nThen B car got on its way. The direct path will certainly lead to collision, so add B car to obstacle and sample around it:\nE car comes and covers one of the point in the graph above. Add E car to obstacle as well.\nA car then comes and stands on one of the …","date":1654992e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654992e3,"objectID":"2557c694d31a1fff0625d19d0bfc7bf9","permalink":"https://gfchen01.github.io/post/visibility-graph-based-mapping-planning-algorithm-for-robocup-ssl/","publishdate":"2022-06-12T00:00:00Z","relpermalink":"/post/visibility-graph-based-mapping-planning-algorithm-for-robocup-ssl/","section":"post","summary":"A novel planning algorithm based on visibility of obstacles on the field.","tags":null,"title":"A Mapping \u0026 Planning Algorithm for RoboCup Small Size League","type":"post"},{"authors":null,"categories":null,"content":"TinySQL is a database management system supporting SQL. The project is self contained and designed originally. Guofei Chen was the architect of the project, as well as the code reviewer.\nHere let’s briefly talk about the design details of this SQL project.\nDownload the Chinese technical report .\nArchitecture This is the architecture of the database. The meaning of arrow is: If A-\u0026gt;B, then A module will use functions and classes in B module. To have a detailed understanding of the relations between modules, please refer to our documentation.\nThe duty of different modules: Interface: Deal with the syntax tree given by SQL-Parser，judge the exact operation type of the command（e.g., create，select, etc.) Transfer the table name, the attribute to project on, and the key value to look for. Give them to the executor.\nExecutor: Determine the execution order, and finish atomic operations.\nCatalog Manager: Manage the basic information of table, including its name, attributes, whether there are indexes on certain attribute, etc.\nIndex Manager : Manage the index file store on the disk. To be specific, we use B+ tree for index.\nRecord Manager : Manage the data of different tables. We store different tables in different files and use row-based mechanism to design the file structure.\nBuffer Manager : Manage the data stored in cache(memory) and its relation with disk files. For modules above, “files” and “memory” are invisible.\nAn overview of important design details This is a row-based database, and use tuple to manage files. We delete records lazily and optimize the file on a regular basis to constrain its size. Storage mechanisms: a. Record Manager: Tables are stored seperately in different binary files. Pages in the file is constrained to be 4KB. b. Index Manager: Indexes are stored seperately in different binary files. The structure of a page is: | BlockType (4) | ParentBlockId(4) | CurrentSize (4) | MaxSize (4) | ParentBlockId (4) | BlockId(4) | key-id pairs… (to 4096B) c. Catalog Manager: A string file stores the information of each table. The information can be decoded by catalog manager, and is readable (to some extent). We only support data records that are smaller than 4KB, which is a page size. An external parser is used in source code. You can find their work here Please star our project on github if you like it! ","date":1654387200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654387200,"objectID":"f0ccc589e294057a7a9e915c08742a7d","permalink":"https://gfchen01.github.io/project/tinysql/","publishdate":"2022-06-05T00:00:00Z","relpermalink":"/project/tinysql/","section":"project","summary":"A Relational Database from Scratch","tags":null,"title":"TinySQL","type":"project"},{"authors":null,"categories":null,"content":"Soft Sensor Using Gaussian Mixture Variational Auto-Encoder : Embed Unsupervised Category Introduction VAE is widely used in process industry for a long time. However, these works mostly focus on the nonlinear feature, and the complex dynamic processes with multi-mode characteristics are seldomly considered. Gaussian Mixture VAE(GM-VAE) can capture the multi-mode character of process, but in the GM-VAE put-forward before, an important structure is erroneous (in the view point of Bayesian Inference). I have fixed this issue using Gumbel-Softmax reparameterization and improved the model’s performance.\nThis work is advised by Prof. Ge at Zhejiang University. I deeply appreciate his help, and you can follow his work on Google Scholar (10k+ citations). link\nFor those who are familiar with VAE, please directly jump to Part IV: Unsupervised Categories and Multi-mode: GM-VAE. But I strongly recommend that you read the “why we use VAE in process industry”, to have some insight into our task.\nSoft Sensor “Soft Sensor” can be viewed as the contradiction of “Hard Sensor”. The principle of sensors are based on some physics laws, and modern sensors typically involve circuits. However, there are times when sensor cannot output critical variables at a higher frequency, or online. For example, in process engineering, process variables such as the concentration of product, are critical to controlling the whole process. However, we need to use methods such as liquid chromatography, which will take minutes to finish; or the process is long, and the inspection of a key process variable has a large delay. At the same time, some process variables (the pressure, the temperature) can be measured at a much higher frequency, and has correlation between these variables with those critical variables. This give rise to soft sensor: use data mining to approximate the process model, and infer the critical but hard to measure variables using accessible measurements.\nOne may ask: why don’t directly derive the model? For many chemical processes, we can’t, at least for now. As chemical processes are becoming more and more complicated, using first-principle is untractable in many cases. Instead of “deriving” models and check them using statistical criteria, some “universal” (by universal, I mean it can approximate a large family of functions) models that converge to a set of parameters arises – Machine Learning. This is the topic of the blog.\n**Note that in the article, we use AE and VAE to represent auto-encoder and variational auto-encoder respectively. **\nPreliminaries: Bayesian Inference, VAE, and why using them AE Variational auto-encoders are based on Bayesian Inference, and originated from auto-encoder, a generative unsupervised model. The idea of auto-encoder is quite simple:\nThe key to auto-encoder is the bottle-neck in the middle. The dimension in the middle must be smaller than that of two sides, in hope of “squeezing” the characters from datasets. The design of auto-encoder is intriguing, because it tells us something about “generative”. Auto-encoder doesn’t have good performance, and the structure that brings are much wider use of it are its variants: Stacked Auto-encoder (SAE), Variational Auto-encoder (VAE).\nVAE and Bayesian Inference VAE regards the latent variables generated by encoder as “distributions”, and then sample from them. The loss of the entire system is derived using Bayesian Inference.\nDenote the dataset as $D$, the latent variables as $\\Omega$. $D$ is generated by $\\Omega$. The key idea in Bayesian Inference is that we can estimate how close we are to the truth even if we have no knowledge about the truth. Assume there is a real distribution of the latent variables $\\Omega$, which is $p(\\Omega|D)$; and we infer a distribution of $\\Omega$ using $D$: $q(\\Omega)$ (Actually it’s $q(\\Omega|D)$, but we aren’t going to touch the conditional distribution, so we write in a compact form). Now we need to measure the “distance” between $p(\\Omega|D)$ and $q(\\Omega)$. A reasonable choice is Kullback–Leibler divergence (KL Divergence in short). $$ D_{KL}(q(\\Omega)||p(\\Omega|D)) = E_{q(\\Omega)}(log\\frac{q(\\Omega)}{p(\\Omega|D)})\\ =\\int q(\\Omega)log\\frac{q(\\Omega)p(D)}{p(D|\\Omega)p(\\Omega)}d\\Omega \\qquad (bayesian\\ rule)\\ =D_{KL}(q(\\Omega)||p(\\Omega)) - \\int q(\\Omega)log\\ p(D|\\Omega)d\\Omega + log\\ p(D) $$ The last term is a constant. Omit it. Define Evidence Lower Bound (ELBO) : $$ ELBO :=-D_{KL}(q(\\Omega)||p(\\Omega)) + \\int q(\\Omega)log\\ p(D|\\Omega)d\\Omega $$ By maximizing ELBO, we can minimize the KL Divergence between $q(\\Omega)$ and $p(\\Omega|D)$. The next question is how to estimate these terms. For simplicity, assume $\\Omega$ admits a conditional gaussian distribution given $D$, then the first term can be transformed into a regularization term. You can find the detailed reasoning in appendix. As for the second term, it’s impossible to accurately calculate the integral here, but we can sample from the distribution of …","date":1642896e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642896e3,"objectID":"d5a720380cdf8110913b2b977fdfb8b9","permalink":"https://gfchen01.github.io/post/gmm_vae/","publishdate":"2022-01-23T00:00:00Z","relpermalink":"/post/gmm_vae/","section":"post","summary":"The answer is - Gumbel-Softmax!","tags":null,"title":"Improving the Sampling in Gaussian Mixture Varitional Encoder - An Important but Easy to Ignore Step","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://gfchen01.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"}]